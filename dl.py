import torch
import torch.nn as nn
import torch.optim as optim
import pytorch_lightning as pl
import albumentations as A
from albumentations.pytorch import ToTensorV2
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from pathlib import Path
import numpy as np

torch.set_float32_matmul_precision('high')

# Config
BATCH_SIZE = 256
NUM_WORKERS = 2
SIZE_H = SIZE_W = 128
NUM_CLASSES = 2
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Albumentations Augmentations
train_transforms = A.Compose([
    A.Resize(height=SIZE_H, width=SIZE_W),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

val_transforms = A.Compose([
    A.Resize(height=SIZE_H, width=SIZE_W),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

# Dataset Wrapper
class AlbumentationsDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, transform):
        self.dataset = dataset
        self.transform = transform
    
    def __getitem__(self, index):
        image, label = self.dataset[index]
        image = np.array(image)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤ –¥–ª—è Albumentations
        image = self.transform(image=image)['image']
        return image, label
    
    def __len__(self):
        return len(self.dataset)

# Model Definition
class CNNModel(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –≤ –¥–≤–∞ —Ä–∞–∑–∞
            
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # –£–º–µ–Ω—å—à–∞–µ–º –µ—â–µ —Ä–∞–∑
             
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # –ï—â–µ –æ–¥–Ω–æ —É–º–µ–Ω—å—à–µ–Ω–∏–µ
        )
        
        # –î–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, –ø—Ä–æ—Ö–æ–¥–∏–º —á–µ—Ä–µ–∑ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–ª–æ–∏
        with torch.no_grad():
            dummy_input = torch.randn(1, 3, SIZE_H, SIZE_W).to(DEVICE)
            output = self.conv_layers(dummy_input)
            conv_output_size = output.numel()  # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —Ç–µ–Ω–∑–æ—Ä–µ –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–∫–∏
            print(f"Output shape after convolutions: {output.shape}, numel: {conv_output_size}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è
        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(conv_output_size, 256),  # –ó–¥–µ—Å—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–∫–∏
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, NUM_CLASSES),
        )
        self.loss_fn = nn.CrossEntropyLoss()
    
    def forward(self, x):
        x = self.conv_layers(x)
        x = self.fc_layers(x)
        return x
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        x = x.to(DEVICE)  # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ GPU, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        preds = self(x)
        loss = self.loss_fn(preds, y)
        acc = (preds.argmax(dim=1) == y).float().mean()
        self.log('train_loss', loss, prog_bar=True)
        self.log('train_acc', acc, prog_bar=True)
        return loss
    
    def validation_step(self, batch, batch_idx):
        x, y = batch
        x = x.to(DEVICE)  # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ GPU, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        preds = self(x)
        loss = self.loss_fn(preds, y)
        acc = (preds.argmax(dim=1) == y).float().mean()
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)
        return loss
    
    def configure_optimizers(self):
        return optim.Adam(self.parameters(), lr=0.001)

if __name__ == "__main__":
    DATA_PATH = Path("data").resolve()
    train_dataset = ImageFolder(DATA_PATH / "train_11k")
    val_dataset = ImageFolder(DATA_PATH / "val")

    train_dataset = AlbumentationsDataset(train_dataset, train_transforms)
    val_dataset = AlbumentationsDataset(val_dataset, val_transforms)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º pin_memory=True –∏ persistent_workers=True –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    train_loader = DataLoader(
        train_dataset, batch_size=BATCH_SIZE, shuffle=True, 
        num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True
    )
    val_loader = DataLoader(
        val_dataset, batch_size=BATCH_SIZE, shuffle=False, 
        num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True
    )

    model = CNNModel().to(DEVICE)  # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    trainer = pl.Trainer(max_epochs=30, accelerator="gpu" if torch.cuda.is_available() else "cpu")
    trainer.fit(model, train_loader, val_loader)
    print("–ì–æ—Ç–æ–≤–æ! –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ üöÄ")

